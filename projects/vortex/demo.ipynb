{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VORTEX\n",
    "**Brief:** Build an interactive application for testing different models under distribution shifts.\n",
    "\n",
    "Common acquisition-related perturbations in MRI, such as changes in signal-to-noise (SNR) and patient motion, can substantially degrade the quality of the reconstructed images.\n",
    "VORTEX helps mitigate this problem by building invariance to these perturbations during model training. VORTEX also helps reduce the amount of fully-sampled data required for training.\n",
    "\n",
    "In this demo, we will use [Meddlr](https://github.com/ad12/meddlr) and [Meerkat](https://github.com/HazyResearch/meerkat) to build interactive applications to explore how\n",
    "different models perform these two distribution shifts. We will learn how to:\n",
    "\n",
    "- Convert Meddlr datasets to Meerkat dataframes\n",
    "- Use pre-built interfaces in Meerkat to visualize our data\n",
    "- Integrate pre-trained or custom models into Meerkat\n",
    "\n",
    "**Reference:**\n",
    "    Desai et al. VORTEX: Physics-Driven Data Augmentations Using Consistency\n",
    "    Training for Robust Accelerated MRI Reconstruction. MIDL 2022.\n",
    "\n",
    "**Requirements:**\n",
    "- `pip install meerkat-ml meddlr`\n",
    "- `pip install torch torchvision`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import meddlr as mr\n",
    "import meerkat as mk\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Meerkat Server\n",
    "Starting the meerkat server will allow us to interact with the Meerkat application in the notebook.\n",
    "\n",
    "If you do not see a view at the bottom of the notebook, change the `api_port` and `frontend_port` and restart the notebook.\n",
    "\n",
    "**Remote Server:** If you are running this notebook on a remote machine, you will need to forward the api and frontend ports to your local machine:\n",
    "\n",
    "```bash\n",
    "# If api_port = 5000 and frontend_port = 8000\n",
    "ssh -L 5000:localhost:5000 -L 8000:localhost:8000 <user>@<remote-machine>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(APIInfo(api=<fastapi.applications.FastAPI object at 0x2ba03fdc0>, port=5000, server=<meerkat.interactive.server.Server object at 0x2ba2242e0>, name='127.0.0.1', shared=False, process=None, _url=None),\n",
       " FrontendInfo(package_manager='npm', port=8000, name='localhost', shared=False, process=<subprocess.Popen object at 0x2ba224310>, _url=None))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk.gui.start(api_port=5000, frontend_port=8000, dev=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataFrame\n",
    "Meerkat DataFrames help manage complex data types, such as high dimensional images, kspace, etc.\n",
    "\n",
    "Let's convert the mridata Stanford 3D knee FSE test split into a Meerkat DataFrame.\n",
    "The dataset is in the ismrmrd HDF5 format, with an additional field for sensitivity maps (`maps`).\n",
    "\n",
    "Each row in the dataframe will correspond to of axial slices of scans from the knee dataset.\n",
    "Columns will include:\n",
    "\n",
    "- `kspace`: The full-sampled kspace for the `ky x kz` slice\n",
    "- `target`: The ground truth slice\n",
    "- `maps`: The sensitivity maps for the slice\n",
    "\n",
    "**Note:** If you have the dataset downloaded locally with `meddlr`, you can fetch the dataset using `DatasetCatalog`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meddlr.data import DatasetCatalog\n",
    "\n",
    "# mridata Stanford 3D FSE dataset.\n",
    "paths = [\n",
    "    \"https://huggingface.co/datasets/arjundd/mridata-stanford-knee-3d-fse/resolve/main/files/ec00945c-ad90-46b7-8c38-a69e9e801074.h5\",\n",
    "    \"https://huggingface.co/datasets/arjundd/mridata-stanford-knee-3d-fse/resolve/main/files/ee2efe48-1e9d-480e-9364-e53db01532d4.h5\",\n",
    "    \"https://huggingface.co/datasets/arjundd/mridata-stanford-knee-3d-fse/resolve/main/files/efa383b6-9446-438a-9901-1fe951653dbd.h5\",\n",
    "]\n",
    "\n",
    "# If you have the Stanford 3D FSE dataset downloaded locally, you can use this:\n",
    "# dataset_dicts = DatasetCatalog.get(\"mridata_knee_2019_test\")\n",
    "# paths = [d[\"file_name\"] for d in dataset_dicts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arjundd/miniconda3/envs/meerkat_prod/lib/python3.8/site-packages/meerkat/ops/map.py:260: UserWarning: Non-default argument 'row' does not have a corresponding column in the DataFrame. If your function expects a full DataFrame row, pass ``inputs='row'`` to ``map``. Otherwise, please provide an `inputs` mapping or pass a lambda function with a different signature. See map documentation for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Convert paths to the slice dataframe.\n",
    "from meddlr_viz.utils import build_slice_df\n",
    "\n",
    "df = build_slice_df(paths, defer=True)\n",
    "df[\"id\"] = df[\"path\"].apply(lambda x: x.split(\"/\")[-1].split(\".\")[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction Models\n",
    "Meddlr offers several reconstruction models in its Model Zoo and easy-to-use [APIs](https://github.com/ad12/meddlr#-model-zoo).\n",
    "\n",
    "Let's start by using a few pre-trained models from the VORTEX paper. These models are hosted on huggingface in the Meddlr format.\n",
    "Providing the urls for these models will automatically download and load them in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-trained models from the VORTEX paper.\n",
    "# More pre-trained models are available at https://github.com/ad12/meddlr/blob/main/projects/vortex/MODEL_ZOO.md\n",
    "MODELS = {\n",
    "    \"Supervised\": \"https://huggingface.co/arjundd/noise2recon-release/resolve/main/mridata_knee_3dfse/12x/Supervised_1sub\",\n",
    "    \"Supervised + Aug\": \"https://huggingface.co/arjundd/vortex-release/resolve/main/mridata_knee_3dfse/Aug_Physics\",\n",
    "    \"SSDU\": \"https://huggingface.co/arjundd/vortex-release/resolve/main/mridata_knee_3dfse/SSDU\",\n",
    "    \"VORTEX\": \"https://huggingface.co/arjundd/vortex-release/resolve/main/mridata_knee_3dfse/VORTEX_Physics\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Adding your own models\n",
    "\n",
    "Interested in using your own models? No problem! Just write a wrapper module for your model.\n",
    "\n",
    "Let's make a dummy model that takes in kspace and returns the zero-filled reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from typing import Dict\n",
    "from meddlr.forward.mri import SenseModel\n",
    "\n",
    "class ZeroFilledModel(nn.Module):\n",
    "    def forward(self, inputs: Dict[str, torch.Tensor]):\n",
    "        A = SenseModel(inputs[\"maps\"], weights=inputs[\"mask\"])\n",
    "        return A(inputs[\"kspace\"], adjoint=True)\n",
    "\n",
    "MODELS[\"Dummy Model\"] = ZeroFilledModel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MRIPerturbationInference` Interface\n",
    "\n",
    "We added `MRIPerturbationInference` to Meerkat's suite of pre-build interfaces.\n",
    "\n",
    "In this interface we can:\n",
    "- Interactively control the SNR, 1D translational motion extent, and acceleration we apply to the k-space\n",
    "- Toggle what models we want to test\n",
    "- Change the scans that we want to visualize\n",
    "\n",
    "This interface gives a quick way to visualize results from your models without having the overhead of writing the scans to disk.\n",
    "\n",
    "**Note:** All reconstructions are computed dynamically. If you are using a CPU, this may take a while. If you have access to a GPU, we recommend using it for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://localhost:8000/?id=MRIPerturbationInference6acfddfb-c8f0-4dbf-8fc6-6e715bb07f30\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2be5bbfa0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from meddlr_viz.gui.perturbation import MRIPerturbationInference\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "view = MRIPerturbationInference(df, models=MODELS, acc=(12, 24, 1))\n",
    "view._get_ipython_height = lambda: \"600px\"\n",
    "\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meddlr_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
